{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.865937\n",
       "1    0.134063\n",
       "Name: spam, dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "#read data for spam.csv\n",
    "data_kaggle = pd.read_csv('spam.csv', header=0, encoding='latin1')\n",
    "\n",
    "#check the column and create the 'spam' column\n",
    "print(data_kaggle.columns)\n",
    "data_kaggle['spam']=(data_kaggle['v1']=='spam').astype('int32')\n",
    "\n",
    "#drop the unwanted column and drop the NA column\n",
    "data_kaggle = data_kaggle.drop(['v1','Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],1)\n",
    "data_kaggle.columns = ['sms','spam']\n",
    "data_kaggle.dropna(how='any')\n",
    "\n",
    "#check out the data and data's distribution.\n",
    "len(data_kaggle)\n",
    "data_kaggle['spam'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make the train data and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=data_kaggle['sms']\n",
    "Y=data_kaggle['spam']\n",
    "\n",
    "X_train, X_test,y_train,y_test=train_test_split(X,Y,test_size=0.33)\n",
    "# Because I define spam value is '1' in 'spam' column, define SPAM is '1'\n",
    "SPAM = 1\n",
    "\n",
    "#create the class consisted with body(=email content) and label(='spam' or 'ham')\n",
    "class Dataset:\n",
    "    def __init__(self,X,Y):\n",
    "        self.body=X\n",
    "        self.label=Y\n",
    "\n",
    "#make the train_list data\n",
    "trainData=[]\n",
    "for index in range(len(X_train)-1):\n",
    "    try:\n",
    "        data_ex=Dataset(X_train[index], y_train[index])\n",
    "        trainData.append(data_ex)\n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of spam : 0.1348\n",
      "ratio of ham : 0.8652\n",
      "46979 words are for spam\n",
      "154336 words are for ham\n"
     ]
    }
   ],
   "source": [
    "# create variables for processEmail function\n",
    "trainPositive=pd.DataFrame()\n",
    "trainNegative=pd.DataFrame()\n",
    "positiveTotal = 0\n",
    "negativeTotal = 0\n",
    "\n",
    "#train function return the ratio of spam and ham in training dataset\n",
    "def train():\n",
    "    total = 0\n",
    "    numSpam = 0\n",
    "    for email in trainData:\n",
    "        if email.label == SPAM :\n",
    "            numSpam +=1\n",
    "        total += 1\n",
    "        processEmail(email.body , email.label)\n",
    "    pA = numSpam/float(total)\n",
    "    pNotA = (total - numSpam)/float(total)\n",
    "    return pA, pNotA\n",
    "\n",
    "#reading words from a specific email\n",
    "def processEmail(body , label):\n",
    "    for word in body:\n",
    "        if label == SPAM:\n",
    "            trainPositive[word] = trainPositive.get(word, 0) + 1  #the number of word(token) repeat.\n",
    "            global positiveTotal\n",
    "            positiveTotal += 1      #total spam words number\n",
    "        else:\n",
    "            trainNegative[word] = trainNegative.get(word, 0) + 1  #the number of word(token) repeat.\n",
    "            global negativeTotal\n",
    "            negativeTotal += 1    #total ham words number\n",
    "\n",
    "pA, pNotA = train()\n",
    "print('ratio of spam : %s'%pA)\n",
    "print('ratio of ham : %s'%pNotA)\n",
    "print('%s words are for spam'%positiveTotal)\n",
    "print('%s words are for ham'%negativeTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gives the conditional probability p(B_i/A_x)\n",
    "#the each token has the probability for 'spam' or 'ham'\n",
    "#the result is the multiplication of each token.\n",
    "def conditionalEmail(body , spam) :\n",
    "    result =1.0\n",
    "    for word in body:\n",
    "        result *= conditionalWord(body , spam)\n",
    "    return result\n",
    "\n",
    "#classifies a new email as spam or not spam\n",
    "def classify(email):\n",
    "    isSpam = pA * conditionalEmail(email, True) # P (A | B)\n",
    "    notSpam = pNotA * conditionalEmail(email, False) # P(Â¬A | B)\n",
    "    return isSpam > notSpam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Laplace Smoothing for the words not present in the training set\n",
    "# the alpha is 1. this value is for 0 frequency\n",
    "alpha=1\n",
    "\n",
    "# for total number of words, first, i crean up the str such as '....',non alphabet.\n",
    "# we make the all words lowercase\n",
    "def clean_str(string):\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\",\", \" \", string)\n",
    "    string = re.sub(r\"!\", \" \", string)\n",
    "    string = re.sub(r\"\\(\", \" \", string)\n",
    "    string = re.sub(r\"\\)\", \" \", string)\n",
    "    string = re.sub(r\"\\?\", \" \", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "# make the vocab(unique words) and count words of vocab\n",
    "vocab_list=[]\n",
    "for i in range(len(data_kaggle)):\n",
    "    str_raw=clean_str(data_kaggle['sms'][i])\n",
    "    token=str_raw.split()\n",
    "    vocab_list+=token\n",
    "vocab = set(vocab_list)\n",
    "numWords = len(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gives the conditional probability p(B_i | A_x) with smoothing\n",
    "def conditionalWord(word, spam):\n",
    "    if spam:\n",
    "        return (trainPositive.get(word,0)+alpha)/(float)(positiveTotal+alpha*numWords)\n",
    "    return (trainNegative.get(word,0)+alpha)/(float)(negativeTotal+alpha*numWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make the test data list like training data\n",
    "testData=[]\n",
    "for index in range(len(X_test)-1):\n",
    "    try:\n",
    "        data_ex=Dataset(X_test[index], y_test[index])\n",
    "        testData.append(data_ex)\n",
    "    except:\n",
    "        continue\n",
    "# for evaluation of our filter, count the hit and calculate the hit ratio.\n",
    "hit = 0\n",
    "for email_test in testData:\n",
    "    predict = classify(email_test.body)\n",
    "    if predict==email_test.label:\n",
    "        hit+=1\n",
    "hit_ratio = float(hit/len(testData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.38305084745762713\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : %s'%hit_ratio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
